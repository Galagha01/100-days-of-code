{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPoxK6nd7wFIG7GHXEU4Huz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Galagha01/100-days-of-code/blob/master/Alagha_Gabriel_Pandas_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg6R2Dq_8LR3"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\"Dataset shape:\", df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "934828f6"
      },
      "source": [
        "Here is the content of the file `/content/pandas_exploratory_data_analysis.md`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df4c8969"
      },
      "source": [
        "**Pandas Exploratory Data Analysis**\n",
        "\n",
        "Exploratory Data Analysis (EDA) is a crucial step in the data science pipeline. It involves summarizing, visualizing, and understanding the main characteristics of a dataset. Pandas, a powerful data manipulation library in Python, provides excellent tools for performing EDA.\n",
        "\n",
        "**Loading Data**\n",
        "\n",
        "The first step is to load your data into a pandas DataFrame. You can load data from various sources like CSV files, Excel spreadsheets, databases, and more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c0742da"
      },
      "source": [
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Display the last 5 rows\n",
        "print(df.tail())\n",
        "\n",
        "# Get the shape of the DataFrame (number of rows and columns)\n",
        "print(df.shape)\n",
        "\n",
        "# Get the total number of data points\n",
        "print(df.size)\n",
        "\n",
        "# Get column names and their data types\n",
        "print(df.dtypes)\n",
        "\n",
        "# Get detailed information about the DataFrame, including non-null counts and memory usage\n",
        "print(df.info())\n",
        "\n",
        "# Get the index of the DataFrame\n",
        "print(df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7ac6f52"
      },
      "source": [
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Get summary statistics for numerical columns (count, mean, std, min, max, quartiles)\n",
        "print(df.describe())\n",
        "\n",
        "# Get summary statistics for categorical columns (count, unique, top, freq)\n",
        "print(df.describe(include='object'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fac5cf2"
      },
      "source": [
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull())\n",
        "\n",
        "# Count missing values per column\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values\n",
        "# df.dropna(inplace=True)\n",
        "\n",
        "# Fill missing values with a specific value\n",
        "# df.fillna(value, inplace=True)\n",
        "\n",
        "# Fill missing values with the mean of the column\n",
        "# df.fillna(df.mean(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ac41a3"
      },
      "source": [
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Check for duplicate rows\n",
        "print(df.duplicated())\n",
        "\n",
        "# Count duplicate rows\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "# Drop duplicate rows\n",
        "# df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Rename columns\n",
        "# df.rename(columns={'old_name': 'new_name'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6730ed56"
      },
      "source": [
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Get unique values in a column\n",
        "print(df['sex'].unique())\n",
        "\n",
        "# Get the number of unique values in a column\n",
        "print(df['sex'].nunique())\n",
        "\n",
        "# Get value counts for a column\n",
        "print(df['sex'].value_counts())\n",
        "\n",
        "# Group data by a column and calculate the mean of another column\n",
        "print(df.groupby('day')['total_bill'].mean())\n",
        "\n",
        "# Create a pivot table\n",
        "print(df.pivot_table(values='total_bill', index='day', columns='time', aggfunc='mean'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ca2004f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Create a histogram\n",
        "df['total_bill'].hist()\n",
        "plt.xlabel('Total Bill')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Total Bill')\n",
        "plt.show()\n",
        "\n",
        "# Create a box plot\n",
        "sns.boxplot(x='day', y='total_bill', data=df)\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Total Bill')\n",
        "plt.title('Box Plot of Total Bill by Day')\n",
        "plt.show()\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(df['total_bill'], df['tip'])\n",
        "plt.xlabel('Total Bill')\n",
        "plt.ylabel('Tip')\n",
        "plt.title('Scatter Plot of Total Bill vs Tip')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Dataset Information"
      ],
      "metadata": {
        "id": "22r7AE049Gwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First 5 rows of the dataset\n",
        "print(\" These are the first 5 rows of the dataset\")\n",
        "print(df.head())\n",
        "print(\"\\n These are the last 5 rows of the dataset\")\n",
        "print(df.tail())\n",
        "\n",
        "#Display dataset as dataframe\n",
        "print(\"\\n\\n This is the dataframe\")\n",
        "display(df)\n",
        "\n",
        "#Shape of the dataset\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "\n",
        "#Total size of the dataset\n",
        "print(\"\\nTotal size of the dataset:\", df.size)\n",
        "\n",
        "print(\"\\n All column names and their data types:\\n\",df.dtypes,\"\\n\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VewVywH89LTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   How many restaurant bills are included in this dataset? 244\n",
        "2.   How many features (columns) does each bill record have? 7\n",
        "1.   What is the total number of data points in the dataset? 244\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jPdhOwHbAz-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Detailed Info of the dataset\n",
        "print(df.info())\n",
        "\n",
        "# Get the index of the DataFrame\n",
        "index_row = df.index\n",
        "print(\"Index of the DataFrame:\", index_row)"
      ],
      "metadata": {
        "id": "XrUMBtJbE-2B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}