{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPeyZCXZjg6XlK04kFh+jQz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Galagha01/100-days-of-code/blob/master/Alagha_Gabriel_Pandas_Intro_to_Series_and_Dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TLFtpj7132X"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Check versions (run this to ensure compatibility)\n",
        "print(\"Pandas version:\", pd.__version__)\n",
        "print(\"NumPy version:\", np.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Temperature Series"
      ],
      "metadata": {
        "id": "Vr4NMZyBBZES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperatures = [68, 72, 75, 71, 69, 73, 76, 78, 74, 70]\n",
        "\n",
        "Temperature_F = pd.Series(temperatures,name = \"Temperature_F\")\n",
        "display(Temperature_F)\n",
        "\n",
        "# Shape of the series\n",
        "display(Temperature_F.shape)\n",
        "\n",
        "# Data type of the series\n",
        "display(Temperature_F.dtype)\n",
        "\n",
        "# Type of the index\n",
        "display(Temperature_F.index.dtype)\n",
        "\n",
        "# Conversion to Celcius\n",
        "Temperature_C = (Temperature_F - 32) * 5/9\n",
        "display(Temperature_C)\n",
        "\n",
        "Temperature_F.head(3)\n",
        "display(Temperature_F.head(3))\n",
        "\n",
        "Temperature_F.mean()\n",
        "display(Temperature_F.mean())\n",
        "\n",
        "Temperature_F.median()\n",
        "display(Temperature_F.median())\n",
        "\n",
        "Temperature_F.min()\n",
        "display(Temperature_F.min())\n",
        "\n",
        "Temperature_F.max()\n",
        "display(Temperature_F.max())\n",
        "\n"
      ],
      "metadata": {
        "id": "00Vq_A-f8Hx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions to answer for each Series:\n",
        "\n",
        "\n",
        "\n",
        "*   What is the shape of the Series? (10,)\n",
        "*   What is the data type? Integer\n",
        "*   What type of index does it have? int64\n",
        "*   Print the first 3 values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xBnstJHPqYVL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Student Grade Series"
      ],
      "metadata": {
        "id": "d7hz3O2iBTcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_grades = pd.Series([92, 87, 94, 91], index=['Alice', 'Bob', 'Charlie', 'Diane'],name = \"student_grades\" )\n",
        "\n",
        "display(student_grades)\n",
        "display(student_grades.shape)\n",
        "display(student_grades.dtype)\n",
        "display(student_grades.index.dtype)"
      ],
      "metadata": {
        "id": "jO0WtVBF81_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the first 3 values\n",
        "\n",
        "*   What is the shape of the Series? (4,)\n",
        "*   What is the data type? Integer\n",
        "*   What type of index does it have? Range\n"
      ],
      "metadata": {
        "id": "L4_obfhcdkSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Daily Steps Series"
      ],
      "metadata": {
        "id": "XsYhCyTlBKhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "daily_steps = pd.Series([8500, 7200, 9100, 6800, 7500, 12000, 11500], index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
        "\n",
        "print(daily_steps)"
      ],
      "metadata": {
        "id": "7SKnBOe6_sCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employee_Records = {\"employee_id\": [101, 102, 103, 104, 105],\n",
        "            \"name\": ['John Smith', 'Jane Doe', 'Bob Johnson', 'Alice Williams', 'Charlie Brown'],\n",
        "            \"department\": ['IT', 'HR', 'Finance', 'IT', 'Marketing'],\n",
        "            \"salary\": [75000, 68000, 72000, 80000, 65000],\n",
        "            \"years_experience\": [5, 3, 7, 6, 2]}\n",
        "\n",
        "\n",
        "# You can create a data frame from a dictionary\n",
        "my_df = pd.DataFrame(employee_Records)\n",
        "\n",
        "print(type(my_df))\n",
        "display(my_df)\n",
        "print(my_df.info())\n",
        "print(my_df.describe())\n",
        "print(my_df['department'].count())\n",
        "print(my_df.isnull())\n",
        "print(pd.unique(my_df['department']))"
      ],
      "metadata": {
        "id": "rRb-Uh_PeQ-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of lists\n",
        "data = [\n",
        "    ['Laptop', \"Electronics\", \"$999.99\", 25],\n",
        "    ['Mouse', \"Electronics\", \"$29.99\",150],\n",
        "    ['Desk Chair', \"Furniture\", \"$199.99\",45],\n",
        "    ['Monitor', \"Electronics\", \"$299.99\",30],\n",
        "    ['Keyboard', \"Electronics\", \"$79.99\",80]\n",
        "    ]\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data, columns=['Name', 'Type', 'Cost', 'Qty'])\n",
        "\n",
        "# Convert 'Cost' column to numeric after removing '$'\n",
        "df['Cost'] = df['Cost'].replace({'\\$': ''}, regex=True).astype(float)\n",
        "\n",
        "display(df)\n",
        "display(df.describe())\n",
        "print(df['Type'].count())\n",
        "\n",
        "# Find the index of the most expensive product from the other DataFrame (df)\n",
        "most_expensive_index = df['Cost'].idxmax()\n",
        "\n",
        "# Find the index of the cheapest product from the other DataFrame (df)\n",
        "cheapest_index = df['Cost'].idxmin()\n",
        "\n",
        "# Get the row for the most expensive product\n",
        "most_expensive_product = df.loc[most_expensive_index]\n",
        "\n",
        "# Get the row for the cheapest product\n",
        "cheapest_product = df.loc[cheapest_index]\n",
        "\n",
        "print(\"\\nMost Expensive Product:\")\n",
        "display(most_expensive_product)\n",
        "\n",
        "print(\"\\nCheapest Product:\")\n",
        "display(cheapest_product)"
      ],
      "metadata": {
        "id": "FSDPspuyiSER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample NumPy array\n",
        "np.random.seed(42)\n",
        "# Generate random integers for sales data\n",
        "sales_data = np.random.randint(100, 1000, (6, 4))\n",
        "\n",
        "# Create DataFrame\n",
        "# Define column names\n",
        "columns = ['North', 'South', 'East', 'West']\n",
        "# Define index (months)\n",
        "index = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\"]\n",
        "\n",
        "df_sales = pd.DataFrame(sales_data, index=index, columns=columns)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"Sales DataFrame:\")\n",
        "display(df_sales)\n",
        "\n",
        "print(\"\\nFirst 3 rows:\")\n",
        "display(df_sales.head(3))\n",
        "\n",
        "print(\"\\nLast 3 rows:\")\n",
        "display(df_sales.tail(3))\n",
        "\n",
        "print(\"\\nColumn names:\")\n",
        "print(df_sales.columns)\n",
        "\n",
        "print(\"\\nIndex:\")\n",
        "print(df_sales.index)\n",
        "\n",
        "print(\"\\nBasic statistics:\")\n",
        "display(df_sales.describe())"
      ],
      "metadata": {
        "id": "6wx2zfOEnlz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019f359d"
      },
      "source": [
        "# Task\n",
        "Practice selecting data from the `my_df`, `df`, and `df_sales` DataFrames by completing the following tasks:\n",
        "\n",
        "**Column Selection:**\n",
        "- Select just employee names and salaries from `my_df`.\n",
        "- Select product names and prices from `df`.\n",
        "- Select sales data for just 'North' and 'South' regions from `df_sales`.\n",
        "\n",
        "**Row Selection:**\n",
        "- Select employees with ID 102 and 104 from `my_df`.\n",
        "- Select the first 2 products from `df`.\n",
        "- Select sales data for March and April from `df_sales`.\n",
        "\n",
        "**Conditional Selection:**\n",
        "- Find employees with salary > $70,000 from `my_df`.\n",
        "- Find products with stock < 50 from `df`.\n",
        "- Find months where North region sales > 500 from `df_sales`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fff53147"
      },
      "source": [
        "## Column selection\n",
        "\n",
        "### Subtask:\n",
        "Write code to select specific columns from `my_df`, `df`, and `df_sales`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5691107a"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires selecting specific columns from three existing DataFrames (`my_df`, `df`, and `df_sales`). I will write a single code block to perform these selections and display the results as requested.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c65b577a"
      },
      "source": [
        "# Select name and salary from my_df\n",
        "my_df_names_salaries = my_df[['name', 'salary']]\n",
        "display(my_df_names_salaries)\n",
        "\n",
        "# Select Name and Cost from df\n",
        "df_names_costs = df[['Name', 'Cost']]\n",
        "display(df_names_costs)\n",
        "\n",
        "# Select North and South from df_sales\n",
        "df_sales_north_south = df_sales[['North', 'South']]\n",
        "display(df_sales_north_south)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "588f0238"
      },
      "source": [
        "## Row selection\n",
        "\n",
        "### Subtask:\n",
        "Write code to select specific rows from `my_df`, `df`, and `df_sales` using index-based and label-based selection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4c7b1e6"
      },
      "source": [
        "**Reasoning**:\n",
        "Select specific rows from the dataframes using index-based and label-based selection as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "133d130e"
      },
      "source": [
        "# Select employees with ID 102 and 104 from my_df using label-based indexing\n",
        "my_df_indexed = my_df.set_index('employee_id')\n",
        "my_df_selected_employees = my_df_indexed.loc[[102, 104]]\n",
        "\n",
        "# Select the first 2 products from df using index-based slicing\n",
        "df_first_two_products = df.iloc[0:2]\n",
        "\n",
        "# Select sales data for March and April from df_sales using label-based indexing\n",
        "df_sales_mar_apr = df_sales.loc[['Mar', 'Apr']]\n",
        "\n",
        "# Display the three newly created DataFrames\n",
        "display(my_df_selected_employees)\n",
        "display(df_first_two_products)\n",
        "display(df_sales_mar_apr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c278074"
      },
      "source": [
        "## Conditional selection\n",
        "\n",
        "### Subtask:\n",
        "Write code to filter rows based on conditions for `my_df`, `df`, and `df_sales`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eedaa5f"
      },
      "source": [
        "**Reasoning**:\n",
        "Filter the three dataframes based on the given conditions and display the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "748a496f"
      },
      "source": [
        "# Find employees with salary > $70,000 from my_df\n",
        "my_df_high_salary = my_df[my_df['salary'] > 70000]\n",
        "\n",
        "# Find products with stock < 50 from df\n",
        "df_low_stock = df[df['Qty'] < 50]\n",
        "\n",
        "# Find months where North region sales > 500 from df_sales\n",
        "df_sales_north_high = df_sales[df_sales['North'] > 500]\n",
        "\n",
        "# Display the resulting DataFrames\n",
        "display(my_df_high_salary)\n",
        "display(df_low_stock)\n",
        "display(df_sales_north_high)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdc32787"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Column Selection:**\n",
        "    *   Successfully selected 'name' and 'salary' from `my_df`.\n",
        "    *   Successfully selected 'Name' and 'Cost' from `df`.\n",
        "    *   Successfully selected 'North' and 'South' columns from `df_sales`.\n",
        "*   **Row Selection:**\n",
        "    *   Successfully selected employees with IDs 102 and 104 from `my_df`.\n",
        "    *   Successfully selected the first 2 products from `df`.\n",
        "    *   Successfully selected sales data for 'Mar' and 'Apr' from `df_sales`.\n",
        "*   **Conditional Selection:**\n",
        "    *   Successfully filtered `my_df` to find employees with salary > \\$70,000.\n",
        "    *   Successfully filtered `df` to find products with stock < 50.\n",
        "    *   Successfully filtered `df_sales` to find months where North region sales > 500.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The ability to select and filter data based on various criteria is fundamental for further analysis, such as calculating statistics or visualizing trends.\n",
        "*   These filtered DataFrames can now be used for more specific analysis, like examining the characteristics of high-salary employees or low-stock products.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAbh5pHCENGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52c661c6"
      },
      "source": [
        "# Task\n",
        "Add calculated and categorical columns to the `Employee`, `Product`, and `Sales` DataFrames as described in the challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26dcf78b"
      },
      "source": [
        "## Add calculated columns to `my df`\n",
        "\n",
        "### Subtask:\n",
        "Calculate `annual_bonus` and `total_compensation` and add them as new columns to the `my_df` DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0280cfce"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate and add the 'annual_bonus' and 'total_compensation' columns to the `my_df` DataFrame and display the updated DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3e9d4eb"
      },
      "source": [
        "# Calculate annual_bonus and add it as a new column\n",
        "my_df['annual_bonus'] = my_df['salary'] * 0.10\n",
        "\n",
        "# Calculate total_compensation and add it as a new column\n",
        "my_df['total_compensation'] = my_df['salary'] + my_df['annual_bonus']\n",
        "\n",
        "# Display the updated DataFrame\n",
        "display(my_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68c048ae"
      },
      "source": [
        "## Add categorical columns to `my df`\n",
        "\n",
        "### Subtask:\n",
        "Create categorical columns `experience_level` and `salary_tier` based on specified conditions and add them to the `my_df` DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "478d33c1"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the 'experience_level' and 'salary_tier' columns based on the specified conditions using boolean indexing and `np.select` for clarity and efficiency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbf6cf1d"
      },
      "source": [
        "# Create 'experience_level' column\n",
        "conditions_experience = [\n",
        "    my_df['years_experience'] < 3,\n",
        "    (my_df['years_experience'] >= 3) & (my_df['years_experience'] <= 7),\n",
        "    my_df['years_experience'] > 7\n",
        "]\n",
        "choices_experience = ['Entry-level', 'Mid-level', 'Senior-level']\n",
        "my_df['experience_level'] = np.select(conditions_experience, choices_experience, default='Unknown')\n",
        "\n",
        "# Create 'salary_tier' column\n",
        "conditions_salary = [\n",
        "    my_df['salary'] < 70000,\n",
        "    (my_df['salary'] >= 70000) & (my_df['salary'] <= 75000),\n",
        "    my_df['salary'] > 75000\n",
        "]\n",
        "choices_salary = ['Tier 1', 'Tier 2', 'Tier 3']\n",
        "my_df['salary_tier'] = np.select(conditions_salary, choices_salary, default='Unknown')\n",
        "\n",
        "# Display the updated DataFrame\n",
        "display(my_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfc9a5d7"
      },
      "source": [
        "## Add calculated columns to `df`\n",
        "\n",
        "### Subtask:\n",
        "Calculate `total_inventory_value` and add it as a new column to the `df` DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "268f2add"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the total inventory value by multiplying the 'Cost' and 'Qty' columns and add it as a new column to the `df` DataFrame. Then, display the updated DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "880b5bb4"
      },
      "source": [
        "# Calculate total_inventory_value\n",
        "df['total_inventory_value'] = df['Cost'] * df['Qty']\n",
        "\n",
        "# Display the updated DataFrame\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dceaf010"
      },
      "source": [
        "## Add categorical columns to `df`\n",
        "\n",
        "### Subtask:\n",
        "Create categorical columns `stock_level` and `price_category` based on specified conditions and add them to the `df` DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53788c95"
      },
      "source": [
        "**Reasoning**:\n",
        "Define conditions and choices for 'stock_level' and 'price_category' columns and use np.select to create these columns in the `df` DataFrame. Finally, display the updated DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4d50618"
      },
      "source": [
        "# Define conditions for creating the stock_level column\n",
        "conditions_stock = [\n",
        "    df['Qty'] > 100,\n",
        "    (df['Qty'] >= 50) & (df['Qty'] <= 100),\n",
        "    df['Qty'] < 50\n",
        "]\n",
        "\n",
        "# Define choices for the stock_level column\n",
        "choices_stock = ['High Stock', 'Medium Stock', 'Low Stock']\n",
        "\n",
        "# Create the stock_level column in the df DataFrame with a default value\n",
        "df['stock_level'] = np.select(conditions_stock, choices_stock, default='Unknown')\n",
        "\n",
        "# Define conditions for creating the price_category column\n",
        "conditions_price = [\n",
        "    df['Cost'] > 500,\n",
        "    (df['Cost'] >= 100) & (df['Cost'] <= 500),\n",
        "    df['Cost'] < 100\n",
        "]\n",
        "\n",
        "# Define choices for the price_category column\n",
        "choices_price = ['High Price', 'Medium Price', 'Low Price']\n",
        "\n",
        "# Create the price_category column in the df DataFrame with a default value\n",
        "df['price_category'] = np.select(conditions_price, choices_price, default='Unknown')\n",
        "\n",
        "# Display the updated df DataFrame\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9938ded5"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because `np.select` requires a `default` value, and without one, it defaults to 0 which doesn't have a compatible dtype with the string choices. I will add a default value of 'Unknown' to `np.select` to fix this issue and then proceed to create both the 'stock_level' and 'price_category' columns as intended.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6cTAOiEEpk1"
      },
      "source": [
        "# Define conditions for creating the stock_level column\n",
        "conditions_stock = [\n",
        "    df['Qty'] > 100,\n",
        "    (df['Qty'] >= 50) & (df['Qty'] <= 100),\n",
        "    df['Qty'] < 50\n",
        "]\n",
        "\n",
        "# Define choices for the stock_level column\n",
        "choices_stock = ['High Stock', 'Medium Stock', 'Low Stock']\n",
        "\n",
        "# Create the stock_level column in the df DataFrame with a default value\n",
        "df['stock_level'] = np.select(conditions_stock, choices_stock, default='Unknown')\n",
        "\n",
        "# Define conditions for creating the price_category column\n",
        "conditions_price = [\n",
        "    df['Cost'] > 500,\n",
        "    (df['Cost'] >= 100) & (df['Cost'] <= 500),\n",
        "    df['Cost'] < 100\n",
        "]\n",
        "\n",
        "# Define choices for the price_category column\n",
        "choices_price = ['High Price', 'Medium Price', 'Low Price']\n",
        "\n",
        "# Create the price_category column in the df DataFrame with a default value\n",
        "df['price_category'] = np.select(conditions_price, choices_price, default='Unknown')\n",
        "\n",
        "# Display the updated df DataFrame\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b27fd40a"
      },
      "source": [
        "## Add calculated columns to `df sales`\n",
        "\n",
        "### Subtask:\n",
        "Calculate `total_monthly_sales` and add it as a new column to the `df_sales` DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dcd7e3d"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the sum of sales across all regions for each month and add it as a new column 'total_monthly_sales' to the df_sales DataFrame, then display the updated DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "316a149a"
      },
      "source": [
        "# Calculate the sum of sales across all regions for each month\n",
        "df_sales['total_monthly_sales'] = df_sales[['North', 'South', 'East', 'West']].sum(axis=1)\n",
        "\n",
        "# Display the updated df_sales DataFrame\n",
        "display(df_sales)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da1aed96"
      },
      "source": [
        "## Add categorical columns to `df sales`\n",
        "\n",
        "### Subtask:\n",
        "Determine the `best_region` for each month and add it as a new categorical column to the `df_sales` DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41e00b4c"
      },
      "source": [
        "**Reasoning**:\n",
        "Determine the column name with the maximum value for each row (month) in the 'North', 'South', 'East', and 'West' columns and assign it to a new column named 'best_region', then display the updated dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ca00317"
      },
      "source": [
        "# Find the column name with the maximum value for each row (month)\n",
        "df_sales['best_region'] = df_sales[['North', 'South', 'East', 'West']].idxmax(axis=1)\n",
        "\n",
        "# Display the updated df_sales DataFrame\n",
        "display(df_sales)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d8a0f6f"
      },
      "source": [
        "## Display the updated dataframes\n",
        "\n",
        "### Subtask:\n",
        "Display the `my_df`, `df`, and `df_sales` DataFrames to show the newly added calculated and categorical columns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12a9dc78"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the three dataframes to show the newly added calculated and categorical columns as requested by the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e45f5cbd"
      },
      "source": [
        "display(my_df)\n",
        "display(df)\n",
        "display(df_sales)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd0b82d7"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   `my_df` (Employee data) was updated with two calculated columns: `annual_bonus` (10% of salary) and `total_compensation` (salary + annual bonus).\n",
        "*   `my_df` also gained two categorical columns: `experience_level` (categorized by years of experience) and `salary_tier` (categorized by salary ranges).\n",
        "*   `df` (Product data) received a calculated column `total_inventory_value` (Cost \\* Qty).\n",
        "*   `df` was enhanced with two categorical columns: `stock_level` (categorized by quantity) and `price_category` (categorized by cost).\n",
        "*   `df_sales` (Sales data) was updated with a calculated column `total_monthly_sales` (sum of sales across all regions for each month).\n",
        "*   `df_sales` also includes a categorical column `best_region`, identifying the region with the highest sales for each month using `idxmax(axis=1)`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The addition of these calculated and categorical columns provides a richer dataset for further analysis, enabling segmentation and comparison based on these new attributes.\n",
        "*   The new columns can be used to perform analyses such as correlating experience level with salary tier, identifying high-value inventory items, or analyzing sales performance by the best-performing region.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c233eb16"
      },
      "source": [
        "# Task\n",
        "Analyze the provided data to answer the following questions: Which department has the most consistent salaries? What's the relationship between experience and salary? Which product category is most profitable per unit of stock? Which region shows the most growth from Jan to Jun? What's the month-to-month growth rate for each region? Create a \"performance score\" combining total sales and consistency. Finally, generate a summary report of your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49b1d359"
      },
      "source": [
        "## Data integration - consistent salaries\n",
        "\n",
        "### Subtask:\n",
        "Calculate the standard deviation of salaries for each department in `my_df` and identify the department with the lowest standard deviation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0488c18d"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the standard deviation of salaries for each department and identify the department with the minimum standard deviation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5868a2c8"
      },
      "source": [
        "# Group by department and calculate the standard deviation of salary\n",
        "department_salary_std = my_df.groupby('department')['salary'].std()\n",
        "\n",
        "# Find the department with the lowest standard deviation\n",
        "most_consistent_department = department_salary_std.idxmin()\n",
        "\n",
        "# Display the results\n",
        "print(\"Standard Deviation of Salaries by Department:\")\n",
        "display(department_salary_std)\n",
        "print(f\"\\nDepartment with the most consistent salaries: {most_consistent_department}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40e3b920"
      },
      "source": [
        "## Data integration - experience and salary relationship\n",
        "\n",
        "### Subtask:\n",
        "Analyze the relationship between `years_experience` and `salary` in `my_df`, possibly using correlation or visualization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aded1b9f"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the correlation between 'years_experience' and 'salary' and create a scatter plot to visualize the relationship.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d73a9cd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the correlation coefficient\n",
        "correlation = my_df['years_experience'].corr(my_df['salary'])\n",
        "print(f\"Correlation between Years of Experience and Salary: {correlation}\")\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(my_df['years_experience'], my_df['salary'])\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "plt.title('Relationship between Years of Experience and Salary')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36f027b4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because the `matplotlib.pyplot` library was not imported. I will import it and regenerate the code to calculate correlation and create the scatter plot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF4F8AYIFSA8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the correlation coefficient\n",
        "correlation = my_df['years_experience'].corr(my_df['salary'])\n",
        "print(f\"Correlation between Years of Experience and Salary: {correlation}\")\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(my_df['years_experience'], my_df['salary'])\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "plt.title('Relationship between Years of Experience and Salary')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de7d58f5"
      },
      "source": [
        "## Data integration - profitable product category\n",
        "\n",
        "### Subtask:\n",
        "Group `df` by `Type` and calculate the total profit per unit of stock for each category.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26fb7b33"
      },
      "source": [
        "**Reasoning**:\n",
        "Group the DataFrame `df` by the 'Type' column, calculate the sum of 'total_inventory_value' and 'Qty' for each group, then divide the sum of 'total_inventory_value' by the sum of 'Qty' to get the total profit per unit of stock per category, and finally display the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04fb244a"
      },
      "source": [
        "# Group by 'Type' and calculate the sum of 'total_inventory_value' and 'Qty'\n",
        "grouped_df = df.groupby('Type').agg({\n",
        "    'total_inventory_value': 'sum',\n",
        "    'Qty': 'sum'\n",
        "})\n",
        "\n",
        "# Calculate the total profit per unit of stock per category\n",
        "grouped_df['profit_per_unit_of_stock'] = grouped_df['total_inventory_value'] / grouped_df['Qty']\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "display(grouped_df['profit_per_unit_of_stock'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76b69c1f"
      },
      "source": [
        "## Advanced analysis - regional growth\n",
        "\n",
        "### Subtask:\n",
        "Calculate the sales growth for each region in `df_sales` from January to June.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fa61437"
      },
      "source": [
        "**Reasoning**:\n",
        "Select the sales data for January and June from the df_sales DataFrame for the 'North', 'South', 'East', and 'West' columns, calculate the sales growth, and display the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00735680"
      },
      "source": [
        "# Select sales data for January and June\n",
        "jan_sales = df_sales.loc['Jan', ['North', 'South', 'East', 'West']]\n",
        "jun_sales = df_sales.loc['Jun', ['North', 'South', 'East', 'West']]\n",
        "\n",
        "# Calculate sales growth\n",
        "sales_growth = jun_sales - jan_sales\n",
        "\n",
        "# Display sales growth\n",
        "display(sales_growth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e2dee8c"
      },
      "source": [
        "## Advanced analysis - month-to-month growth rate\n",
        "\n",
        "### Subtask:\n",
        "Calculate the month-to-month growth rate for each region in `df_sales`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10b5504d"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the month-to-month percentage change for each region in the df_sales DataFrame and display the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffdfd168"
      },
      "source": [
        "# Calculate the month-to-month growth rate for each region\n",
        "monthly_growth_rate = df_sales[['North', 'South', 'East', 'West']].pct_change(axis=0)\n",
        "\n",
        "# Display the monthly growth rate DataFrame\n",
        "display(monthly_growth_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52373845"
      },
      "source": [
        "## Advanced analysis - performance score\n",
        "\n",
        "### Subtask:\n",
        "Create a \"performance score\" for each region in `df_sales` by combining total sales and consistency (e.g., using standard deviation of monthly sales).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed4ec12f"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the total sales and standard deviation of sales for each region, then combine these into a performance score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7669710"
      },
      "source": [
        "# Calculate the total sales for each region\n",
        "region_total_sales = df_sales[['North', 'South', 'East', 'West']].sum()\n",
        "\n",
        "# Calculate the standard deviation of monthly sales for each region\n",
        "region_std_sales = df_sales[['North', 'South', 'East', 'West']].std()\n",
        "\n",
        "# Combine the total sales and the inverse of the standard deviation into a performance score\n",
        "# A simple approach: higher total sales is good, lower std deviation is good.\n",
        "# We can use a weighted sum, for simplicity let's use total sales and inverse of std dev.\n",
        "# Add a small epsilon to avoid division by zero if std dev is 0\n",
        "epsilon = 1e-6\n",
        "performance_score = region_total_sales / (region_std_sales + epsilon)\n",
        "\n",
        "# Display the performance scores\n",
        "display(performance_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87e04f36"
      },
      "source": [
        "## Generate summary report\n",
        "\n",
        "### Subtask:\n",
        "Present the findings from steps 1-6 in a clear and concise summary report.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18521dc2"
      },
      "source": [
        "**Reasoning**:\n",
        "Write a summary report in markdown format synthesizing the findings from the previous analysis steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2d5ae41"
      },
      "source": [
        "print(\"## Data Analysis Summary Report\\n\")\n",
        "\n",
        "print(\"### Department with the Most Consistent Salaries\")\n",
        "print(f\"Based on the standard deviation of salaries, the **{most_consistent_department}** department has the most consistent salaries.\")\n",
        "display(department_salary_std)\n",
        "\n",
        "print(\"\\n### Relationship between Years of Experience and Salary\")\n",
        "print(f\"There is a strong positive correlation between years of experience and salary, with a correlation coefficient of approximately **{correlation:.3f}**. This indicates that employees with more experience tend to have higher salaries.\")\n",
        "\n",
        "print(\"\\n### Most Profitable Product Category per Unit of Stock\")\n",
        "print(\"Analyzing the total inventory value per unit of stock, the **Furniture** category is the most profitable per unit of stock.\")\n",
        "display(grouped_df['profit_per_unit_of_stock'])\n",
        "\n",
        "print(\"\\n### Regional Sales Growth from January to June\")\n",
        "print(\"The sales growth from January to June varies by region:\")\n",
        "display(sales_growth)\n",
        "print(\"The **North** region showed the highest absolute growth, while the **South** and **East** regions experienced a decline in sales.\")\n",
        "\n",
        "print(\"\\n### Month-to-Month Growth Rate for Each Region\")\n",
        "print(\"The month-to-month growth rates show the fluctuations in sales for each region throughout the period:\")\n",
        "display(monthly_growth_rate)\n",
        "\n",
        "print(\"\\n### Regional Performance Score\")\n",
        "print(\"The performance score combines total sales and consistency (inverse of standard deviation of monthly sales). A higher score indicates better overall performance.\")\n",
        "display(performance_score)\n",
        "print(\"Based on this score, the **East** and **West** regions appear to have the strongest performance, balancing high total sales with relatively consistent monthly figures.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68345cc7"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "*   **Which department has the most consistent salaries?** The IT department has the most consistent salaries, with the lowest standard deviation.\n",
        "*   **What's the relationship between experience and salary?** There is a strong positive correlation (approximately 0.759) between years of experience and salary, indicating that more experienced employees tend to have higher salaries.\n",
        "*   **Which product category is most profitable per unit of stock?** The Furniture category is the most profitable per unit of stock.\n",
        "*   **Which region shows the most growth from Jan to Jun?** The North region showed the highest absolute sales growth from January to June (559).\n",
        "*   **What's the month-to-month growth rate for each region?** The month-to-month growth rate varies for each region and is presented in a detailed table showing the percentage change from the previous month.\n",
        "*   **Which region has the highest performance score?** Based on the calculated performance score combining total sales and consistency, the East region has the highest score, followed closely by the West region.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The standard deviation of salaries varies across departments, with the IT department having the lowest standard deviation, indicating the most consistent salaries.\n",
        "*   A strong positive correlation of approximately 0.759 exists between years of experience and salary.\n",
        "*   Comparing total inventory value per unit of stock, the Furniture category (approximately \\$199.99 per unit) is more profitable than the Electronics category (approximately \\$157.53 per unit).\n",
        "*   Regional sales growth from January to June shows significant variation: North (559), South (-127), East (-91), and West (73).\n",
        "*   The month-to-month sales growth rate fluctuates for all regions throughout the analyzed period.\n",
        "*   A calculated performance score, which considers both total sales and the inverse of the standard deviation of monthly sales, indicates that the East and West regions have the strongest overall performance.\n",
        "\n"
      ]
    }
  ]
}